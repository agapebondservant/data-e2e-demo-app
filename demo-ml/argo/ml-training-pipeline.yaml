#@ load("@ytt:data", "data")
---
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: random-forest-train-workflow
  annotations:
    kapp.k14s.io/versioned: ""
    kapp.k14s.io/nonce: ""
    kapp.k14s.io/disable-wait: ""
spec:
  schedule: "*/1 * * * *"
  concurrencyPolicy: "Forbid"
  startingDeadlineSeconds: 0
  workflowSpec:
    securityContext:
      runAsUser: 1000
      fsGroup: 1000
    entrypoint: train
    onExit: exit-handler
    templates:
      - name: train
        steps:
          - - name: fetch-git-revision
              template: fetch-git-metadata
          - - name: run-training
              template: deploy-training-db
              arguments:
                parameters:
                  - name: git_sha
                    value: "{{steps.fetch-git-revision.outputs.result}}"
          - - name: publish-model
              template: run-training
              arguments:
                parameters:
                  - name: entrypoint
                    value: "./app/publish_randomforest_model.py"

      - name: fetch-git-metadata
        inputs:
          artifacts:
            - name: git-rev
              path: /tmp
              git:
                repo: #@ data.values.git_repo
                singleBranch: true
                branch: #@ data.values.environment_name
        container:
          image: golang
          command: [sh, -c]
          securityContext:
            runAsUser: 0
            fsGroup: 1000
          args: ["git config --global --add safe.directory /tmp; git rev-parse --short HEAD;"]
          workingDir: /tmp

      - name: exit-handler
        inputs:
          parameters:
            - name: user
              value: #@ data.values.training_user
            - name: db_uri
              value: #@ data.values.training_db_uri
            - name: external_secret_ref
              value: #@ data.values.training_external_secret_ref
            - name: external_secret_ref_key
              value: #@ data.values.training_external_secret_ref_key
        script:
          image: liquibase/liquibase
          env:
            - name: HOST_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.external_secret_ref}}"
                  key: "{{inputs.parameters.external_secret_ref_key}}"
          command: [ bash ]
          source: |
            liquibase releaseLocks \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" \
            --password="${HOST_PASSWORD}";

      - name: deploy-training-db
        inputs:
          artifacts:
            - name: deploy-code-db
              path: "{{inputs.parameters.script_shared_path}}"
              git:
                repo: #@ data.values.git_repo
                singleBranch: true
                branch: #@ data.values.environment_name
          parameters:
            - name: user
              value: #@ data.values.training_user
            - name: db_uri
              value: #@ data.values.training_db_uri
            - name: shared_path
              value: #@ data.values.training_shared_path
            - name: external_secret_ref
              value: #@ data.values.training_external_secret_ref
            - name: external_secret_ref_key
              value: #@ data.values.training_external_secret_ref_key
            - name: git_repo
              value: #@ data.values.git_repo
            - name: git_repo_prefix
              value: #@ data.values.git_repo.replace(".git","")
            - name: environment_name
              value: #@ data.values.environment_name
            - name: script_shared_path
              value: #@ data.values.script_shared_path
            - name: db_script
              value: #@ data.values.training_db_script
            - name: db_schema
              value: #@ data.values.training_db_schema
            - name: shell_script
              value: #@ data.values.training_db_shell_script
            - name: shared_argo_artifact_server
              value: #@ data.values.shared_argo_artifact_server
            - name: shared_argo_artifact_server_bucket
              value: #@ data.values.shared_argo_artifact_server_bucket
            - name: hyperparameters_script
              value: #@ data.values.training_hyperparameters_db_script
            - name: git_sha
        outputs:
          artifacts:
            - name: training-output
              path: changelog/sample.sql
              s3:
                endpoint: "{{inputs.parameters.shared_argo_artifact_server}}"
                insecure: true
                bucket: "{{inputs.parameters.shared_argo_artifact_server_bucket}}"
                key: anomaly-detection/sample.tgz
                accessKeySecret:
                  name: minio
                  key: accesskey
                secretKeySecret:
                  name: minio
                  key: secretkey

        script:
          image: liquibase/liquibase
          mirrorVolumeMounts: true
          env:
            - name: HOST_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.external_secret_ref}}"
                  key: "{{inputs.parameters.external_secret_ref_key}}"
          command: [bash]
          source: |
            set -e;

            DB_SCHEMA="{{inputs.parameters.db_schema}}" \
            SHARED_PATH="{{inputs.parameters.script_shared_path}}" \
            DB_SCRIPT="{{inputs.parameters.hyperparameters_script}}" \
            "{{inputs.parameters.script_shared_path}}"/"{{inputs.parameters.shell_script}}";

            DB_SCHEMA="{{inputs.parameters.db_schema}}" \
            SHARED_PATH="{{inputs.parameters.script_shared_path}}" \
            DB_SCRIPT="{{inputs.parameters.db_script}}" \
            "{{inputs.parameters.script_shared_path}}"/"{{inputs.parameters.shell_script}}";

            liquibase executeSql \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" --password="${HOST_PASSWORD}" \
            --sql="SELECT 'start'";

            liquibase tag --tag="{{inputs.parameters.git_repo_prefix}}/commit/{{inputs.parameters.git_sha}}" \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" \
            --password="${HOST_PASSWORD}";

            liquibase update \
            --changelog-file=changelog/"{{inputs.parameters.hyperparameters_script}}" \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" \
            --password="${HOST_PASSWORD}";

            liquibase update \
            --changelog-file=changelog/"{{inputs.parameters.db_script}}" \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" \
            --password="${HOST_PASSWORD}";

            liquibase executeSql \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" --password="${HOST_PASSWORD}" \
            --sql="SELECT run_random_forest_training()";

            liquibase generateChangeLog \
            --logLevel=INFO \
            --changeLogFile=changelog/sample.sql \
            --url="{{inputs.parameters.db_uri}}" \
            --username="{{inputs.parameters.user}}" --password="${HOST_PASSWORD}" --diff-types="data" \
            --overwrite-output-file=true \
            --include-objects="rf_credit_card_transactions_importances, rf_credit_card_transactions_inference_results, rf_credit_card_transactions_model, rf_credit_card_transactions_model_group, rf_credit_card_transactions_model_summary, rf_model_versions";


      - name: run-training
        inputs:
          parameters:
            - name: entrypoint
            - name: model_name
              value: 'model'
            - name: mlflow_tracking_uri
              value: #@ data.values.mlflow_tracking_uri
            - name: mlflow_s3_uri
              value: #@ data.values.mlflow_s3_uri
            - name: datahub_rest_uri
              value: #@ data.values.datahub_rest_uri
            - name: training_user
              value: #@ data.values.training_user
            - name: training_master
              value: #@ data.values.training_master
            - name: training_db_name
              value: #@ data.values.training_db_name
            - name: inference_user
              value: #@ data.values.inference_user
            - name: inference_host
              value: #@ data.values.inference_host
            - name: inference_db_name
              value: #@ data.values.inference_db_name
            - name: training_external_secret_ref
              value: #@ data.values.training_external_secret_ref
            - name: training_external_secret_ref_key
              value: #@ data.values.training_external_secret_ref_key
            - name: inference_external_secret_ref
              value: #@ data.values.inference_external_secret_ref
            - name: inference_external_secret_ref_key
              value: #@ data.values.inference_external_secret_ref_key
            - name: shared_rabbit_secret
              value: #@ data.values.shared_rabbit_secret
            - name: shared_rabbit_host
              value: #@ data.values.shared_rabbit_host
            - name: shared_argo_events_amqp_exchange
              value: #@ data.values.shared_argo_events_amqp_exchange
            - name: shared_argo_events_amqp_routing_key
              value: #@ data.values.shared_argo_events_amqp_routing_key
            - name: inference_cache_server
              value: #@ data.values.inference_cache_gemfire_server
        container:
          image: oawofolu/demo-ml-base
          command: [ python ]
          securityContext:
            runAsUser: 0
            fsGroup: 1000
          env:
            - name: MLFLOW_TRACKING_URI
              value: "{{inputs.parameters.mlflow_tracking_uri}}"
            - name: MLFLOW_S3_ENDPOINT_URL
              value: "{{inputs.parameters.mlflow_s3_uri}}"
            - name: datahub_rest_uri
              value: "{{inputs.parameters.datahub_rest_uri}}"
            - name: training_user
              value: "{{inputs.parameters.training_user}}"
            - name: training_master
              value: "{{inputs.parameters.training_master}}"
            - name: training_db_name
              value: "{{inputs.parameters.training_db_name}}"
            - name: inference_user
              value: "{{inputs.parameters.inference_user}}"
            - name: inference_host
              value: "{{inputs.parameters.inference_host}}"
            - name: inference_db_name
              value: "{{inputs.parameters.inference_db_name}}"
            - name: training_password
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.training_external_secret_ref}}"
                  key: "{{inputs.parameters.training_external_secret_ref_key}}"
            - name: inference_password
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.inference_external_secret_ref}}"
                  key: "{{inputs.parameters.inference_external_secret_ref_key}}"
            - name: training_db_uri_full
              value: postgresql://"{{inputs.parameters.training_user}}":$training_password@"{{inputs.parameters.training_master}}"/"{{inputs.parameters.training_db_name}}"?sslmode=require
            - name: inference_db_uri_full
              value: postgresql://"{{inputs.parameters.inference_user}}":$inference_password@"{{inputs.parameters.inference_host}}"/"{{inputs.parameters.inference_db_name}}"
            - name: rmq_user
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.shared_rabbit_secret}}"
                  key: username
            - name: rmq_password
              valueFrom:
                secretKeyRef:
                  name: "{{inputs.parameters.shared_rabbit_secret}}"
                  key: password
            - name: rmq_host
              value: "{{inputs.parameters.shared_rabbit_host}}"
            - name: rmq_exchange
              value: "{{inputs.parameters.shared_argo_events_amqp_exchange}}"
            - name: rmq_routing_key
              value: "{{inputs.parameters.shared_argo_events_amqp_routing_key}}"
            - name: inference_cache_server
              value: "{{inputs.parameters.inference_cache_server}}"
          args:
            - "{{inputs.parameters.entrypoint}}"